{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samarth0709/Monte-Carlo-Simulation/blob/main/MC_SIMULATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLFlJns4bamB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# The exclamation mark (!) tells Colab to run a terminal command\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- STEP 1: DOWNLOAD DATA ---\n",
        "# We use the ticker '^NSEI' for Nifty 50\n",
        "print(\"Downloading Nifty 50 Data...\")\n",
        "data = yf.download('^NSEI', start='2023-01-01', end='2024-01-01')\n",
        "\n",
        "# Keep only the 'Close' price column\n",
        "# We use .copy() to avoid SettingWithCopy warnings\n",
        "df = data[['Close']].copy()\n",
        "\n",
        "# --- STEP 2: CALCULATE RETURNS ---\n",
        "\n",
        "# A. Simple Returns (Arithmetic)\n",
        "# Formula: (Price_t / Price_t-1) - 1\n",
        "df['Simple_Return'] = df['Close'].pct_change()\n",
        "\n",
        "# B. Log Returns (Geometric)\n",
        "# Formula: ln(Price_t / Price_t-1)\n",
        "# np.log calculates the natural logarithm\n",
        "df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "\n",
        "# Drop the first row (NaN) because it has no previous day to compare to\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# --- STEP 3: ANALYZE & VISUALIZE ---\n",
        "\n",
        "print(\"\\n--- STATISTICS ---\")\n",
        "print(f\"Mean Daily Log Return: {df['Log_Return'].mean():.6f}\")\n",
        "print(f\"Daily Volatility (Std Dev): {df['Log_Return'].std():.6f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(df.index, df['Log_Return'], label='Daily Log Returns', color='blue', alpha=0.6)\n",
        "plt.axhline(0, color='black', linewidth=0.8, linestyle='--') # Zero line\n",
        "plt.title('Nifty 50 Daily Log Returns (2023)')\n",
        "plt.ylabel('Return')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Visualize the difference (Simple vs Log)\n",
        "print(\"\\nDifference between Simple and Log Returns (First 5 days):\")\n",
        "print(df[['Simple_Return', 'Log_Return']].head())"
      ],
      "metadata": {
        "id": "ciGQSBkMNK57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DAY 2: VOLATILITY ANALYSIS ---\n",
        "\n",
        "# 1. Define the Window (e.g., 30 Trading Days)\n",
        "window_size = 30\n",
        "\n",
        "# 2. Calculate Rolling Standard Deviation (Volatility)\n",
        "# We multiply by sqrt(252) to \"Annualize\" it (make it comparable to interest rates)\n",
        "df['Rolling_Vol'] = df['Log_Return'].rolling(window=window_size).std() * np.sqrt(252)\n",
        "\n",
        "# 3. Plotting Historical Volatility\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(df.index, df['Rolling_Vol'], color='red', label=f'{window_size}-Day Rolling Volatility')\n",
        "\n",
        "plt.title('Nifty 50 Historical Volatility (Annualized)')\n",
        "plt.ylabel('Annualized Volatility (Sigma)')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 4. Print Current Market Risk\n",
        "current_vol = df['Rolling_Vol'].iloc[-1]\n",
        "print(f\"Current Annualized Volatility: {current_vol*100:.2f}%\")"
      ],
      "metadata": {
        "id": "phg5qVKfNy9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DAY 3: BROWNIAN MOTION SIMULATION ---\n",
        "\n",
        "# 1. Setup Parameters (Derived from your Day 2 analysis)\n",
        "S0 = df['Close'].iloc[-1].item()      # Starting Price (The last actual price of Nifty)\n",
        "mu = 0.12                      # Expected Return (Assumed 12% per year)\n",
        "sigma = current_vol            # Volatility (We use the last value from your graph: ~10%)\n",
        "T = 1.0                        # Time horizon (1 Year)\n",
        "dt = 1/252                     # Daily time step\n",
        "N = int(T/dt)                  # Total steps (252 days)\n",
        "\n",
        "# 2. Simulate ONE Path (The \"Random Walk\")\n",
        "# Generate 252 random normal numbers (shocks)\n",
        "np.random.seed(42) # For reproducibility\n",
        "Z = np.random.normal(0, 1, N)\n",
        "\n",
        "# Calculate the path using the GBM Formula\n",
        "# S_t = S_0 * exp( (mu - 0.5*sigma^2)*t + sigma*sqrt(t)*Z )\n",
        "drift = (mu - 0.5 * sigma**2) * dt\n",
        "diffusion = sigma * np.sqrt(dt) * Z\n",
        "daily_returns = np.exp(drift + diffusion)\n",
        "\n",
        "# Create the price path\n",
        "price_path = np.zeros(N)\n",
        "price_path[0] = S0\n",
        "for t in range(1, N):\n",
        "    price_path[t] = price_path[t-1] * daily_returns[t]\n",
        "\n",
        "# 3. Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(price_path, color='green', label='Simulated Future Path')\n",
        "plt.axhline(S0, color='black', linestyle='--', label='Start Price')\n",
        "plt.title(f'One Possible Future for Nifty 50 (GBM)')\n",
        "plt.xlabel('Future Trading Days')\n",
        "plt.ylabel('Simulated Price')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dO3cZ40POO-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TICKER = '^NSEI'       # Nifty 50\n",
        "START_DATE = '2023-01-01'\n",
        "END_DATE = '2024-01-01'\n",
        "CONFIDENCE_LEVEL = 0.95\n",
        "PORTFOLIO_VALUE = 100000  # Rs. 1,00,000 invested\n",
        "\n",
        "# --- STEP 1: DATA PIPELINE ---\n",
        "print(f\"Fetching data for {TICKER}...\")\n",
        "data = yf.download(TICKER, start=START_DATE, end=END_DATE, progress=False)\n",
        "df = data[['Close']].copy()\n",
        "\n",
        "# Calculate Log Returns: ln(Pt / Pt-1)\n",
        "# Log returns are preferred for risk modeling due to time-additivity\n",
        "df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# --- STEP 2: PARAMETRIC VaR (The \"Normal\" Method) ---\n",
        "# Assumption: Returns follow a Gaussian (Normal) Distribution\n",
        "mu = df['Log_Return'].mean()\n",
        "sigma = df['Log_Return'].std()\n",
        "\n",
        "# Calculate Z-score for 5% cutoff (approx -1.645)\n",
        "z_score = stats.norm.ppf(1 - CONFIDENCE_LEVEL)\n",
        "\n",
        "# Parametric VaR Formula: (mu + z * sigma)\n",
        "var_param_pct = mu + (z_score * sigma)\n",
        "var_param_inr = PORTFOLIO_VALUE * var_param_pct\n",
        "\n",
        "# --- STEP 3: HISTORICAL VaR (The \"Real-World\" Method) ---\n",
        "# No assumptions; we let the past data speak for itself\n",
        "# We simply find the 5th percentile of actual past returns\n",
        "var_hist_pct = np.percentile(df['Log_Return'], (1 - CONFIDENCE_LEVEL) * 100)\n",
        "var_hist_inr = PORTFOLIO_VALUE * var_hist_pct\n",
        "\n",
        "# --- BONUS: EXPECTED SHORTFALL (CVaR) ---\n",
        "# \"If we DO cross the VaR threshold, how bad will the crash be?\"\n",
        "# This is the average of all returns worse than the VaR\n",
        "cvar_hist_pct = df[df['Log_Return'] <= var_hist_pct]['Log_Return'].mean()\n",
        "cvar_hist_inr = PORTFOLIO_VALUE * cvar_hist_pct\n",
        "\n",
        "# --- STEP 4: VISUALIZATION ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 1. The Distribution (Histogram)\n",
        "# Bins=50 gives us a granular view of the \"Fat Tails\"\n",
        "plt.hist(df['Log_Return'], bins=50, density=True, alpha=0.6, color='#1f77b4', label='Daily Returns Distribution')\n",
        "\n",
        "# 2. The Density Curve (KDE)\n",
        "# This smooth line shows the \"shape\" of the market\n",
        "df['Log_Return'].plot(kind='kde', color='black', linewidth=1.5, label='Density Curve')\n",
        "\n",
        "# 3. The Risk Thresholds\n",
        "plt.axvline(var_param_pct, color='orange', linestyle='--', linewidth=2, label=f'Parametric VaR (95%): {var_param_pct:.2%}')\n",
        "plt.axvline(var_hist_pct, color='red', linestyle='-', linewidth=2, label=f'Historical VaR (95%): {var_hist_pct:.2%}')\n",
        "\n",
        "# Formatting\n",
        "plt.title(f'Risk Analysis: Nifty 50 Return Distribution ({START_DATE} to {END_DATE})', fontsize=14)\n",
        "plt.xlabel('Daily Log Return', fontsize=12)\n",
        "plt.ylabel('Density / Frequency', fontsize=12)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# --- STEP 5: PROFESSIONAL REPORTING ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"RISK REPORT: {TICKER} (Investment: Rs. {PORTFOLIO_VALUE:,.2f})\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Observation Period: {len(df)} trading days\")\n",
        "print(f\"Daily Volatility:   {sigma:.2%}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"95% Parametric VaR: {var_param_pct:.4%}  | Loss: Rs. {abs(var_param_inr):,.2f}\")\n",
        "print(f\"95% Historical VaR: {var_hist_pct:.4%}  | Loss: Rs. {abs(var_hist_inr):,.2f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"CONDITIONAL VaR (Expected Shortfall):\")\n",
        "print(f\"Avg Loss on Bad Days: {cvar_hist_pct:.4%} | Loss: Rs. {abs(cvar_hist_inr):,.2f}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "riqJ3hTKbk_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TICKER = '^NSEI'        # Nifty 50\n",
        "SIMULATIONS = 1000      # Number of \"Alternate Universes\" to simulate\n",
        "TIME_HORIZON = 252      # Days to simulate (1 Year)\n",
        "START_DATE = '2023-01-01'\n",
        "END_DATE = '2024-01-01'\n",
        "\n",
        "# --- STEP 1: GET HISTORICAL DATA ---\n",
        "print(f\"1. Fetching data for {TICKER}...\")\n",
        "data = yf.download(TICKER, start=START_DATE, end=END_DATE, progress=False)\n",
        "df = data[['Close']].copy()\n",
        "\n",
        "# Calculate Log Returns\n",
        "df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# --- STEP 2: ESTIMATE PARAMETERS (Drift & Volatility) ---\n",
        "# We estimate the model parameters from history\n",
        "mu = df['Log_Return'].mean() * 252      # Annualized Drift (Return)\n",
        "sigma = df['Log_Return'].std() * (252**0.5) # Annualized Volatility\n",
        "S0 = df['Close'].iloc[-1].item()        # Starting Price (Last actual close)\n",
        "\n",
        "print(f\"2. Model Parameters:\")\n",
        "print(f\"   Start Price (S0): {S0:.2f}\")\n",
        "print(f\"   Annual Drift (μ): {mu:.2%}\")\n",
        "print(f\"   Annual Volatility (σ): {sigma:.2%}\")\n",
        "\n",
        "# --- STEP 3: THE MONTE CARLO ENGINE (Vectorized GBM) ---\n",
        "# We simulate 1000 paths at once using Matrix Math (Faster than loops!)\n",
        "\n",
        "# A. Define Time Steps\n",
        "dt = 1/252  # 1 Day step\n",
        "\n",
        "# B. Generate Random Shocks (The \"Wiener Process\")\n",
        "# We create a matrix of size [Days, Simulations] filled with random Z-scores\n",
        "np.random.seed(42) # For reproducibility\n",
        "Z_matrix = np.random.normal(0, 1, (TIME_HORIZON, SIMULATIONS))\n",
        "\n",
        "# C. Apply the Geometric Brownian Motion Formula\n",
        "# Formula: Returns = (mu - 0.5*sigma^2)*dt + sigma*sqrt(dt)*Z\n",
        "drift_term = (mu - 0.5 * sigma**2) * dt\n",
        "diffusion_term = sigma * (dt**0.5) * Z_matrix\n",
        "\n",
        "# Calculate Daily Returns for all 1000 paths at once\n",
        "daily_log_returns = drift_term + diffusion_term\n",
        "\n",
        "# D. Convert Returns to Price Paths\n",
        "# We use cumulative sum (cumsum) to add up returns over time\n",
        "cumulative_returns = np.cumsum(daily_log_returns, axis=0)\n",
        "cumulative_returns = np.vstack([np.zeros((1, SIMULATIONS)), cumulative_returns]) # Add Day 0 (0% return)\n",
        "\n",
        "# S_t = S_0 * exp(Sum of Returns)\n",
        "price_paths = S0 * np.exp(cumulative_returns)\n",
        "\n",
        "# --- STEP 4: VISUALIZATION (The Cone of Uncertainty) ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot the first 50 paths (plotting all 1000 makes it messy)\n",
        "plt.plot(price_paths[:, :50], lw=1, alpha=0.6)\n",
        "\n",
        "# Plot the \"Mean Path\" (The average of all 1000 futures)\n",
        "mean_path = np.mean(price_paths, axis=1)\n",
        "plt.plot(mean_path, color='black', linewidth=3, linestyle='--', label='Average Outcome (Expected Value)')\n",
        "\n",
        "plt.title(f'Monte Carlo Simulation: {SIMULATIONS} Possible Futures for Nifty 50', fontsize=14)\n",
        "plt.xlabel('Future Trading Days', fontsize=12)\n",
        "plt.ylabel('Simulated Price', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# --- STEP 5: PROBABILISTIC ANALYSIS ---\n",
        "# Now we can answer questions like \"What is the chance Nifty crosses 25k?\"\n",
        "final_prices = price_paths[-1, :] # The prices on the very last day\n",
        "\n",
        "prob_profit = np.mean(final_prices > S0)\n",
        "worst_case = np.percentile(final_prices, 5) # 5th Percentile (95% VaR)\n",
        "best_case = np.percentile(final_prices, 95) # 95th Percentile\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"SIMULATION RESULTS (1 Year Forecast)\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Probability of Profit: {prob_profit:.1%}\")\n",
        "print(f\"Expected Price (Avg):  {np.mean(final_prices):.2f}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Optimistic Case (Top 5%): {best_case:.2f}\")\n",
        "print(f\"Pessimistic Case (Bottom 5%): {worst_case:.2f}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "1yjRT9DtcFBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 6: IMPLEMENTING THE GBM ENGINE ---\n",
        "\n",
        "def simulate_gbm(S0, mu, sigma, T, dt, n_sims, seed=42):\n",
        "    \"\"\"\n",
        "    Simulates Geometric Brownian Motion (GBM) price paths.\n",
        "\n",
        "    Parameters:\n",
        "    S0 (float): Initial stock price\n",
        "    mu (float): Annualized drift (expected return)\n",
        "    sigma (float): Annualized volatility\n",
        "    T (float): Time horizon in years\n",
        "    dt (float): Time step size (e.g., 1/252)\n",
        "    n_sims (int): Number of paths to simulate\n",
        "    seed (int): Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    np.array: Matrix of price paths with shape (n_steps + 1, n_sims)\n",
        "    \"\"\"\n",
        "    # 1. Set Seed (Crucial for reproducibility in research)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # 2. Calculate Steps\n",
        "    N = int(T / dt)\n",
        "\n",
        "    # 3. Generate Random Matrix (Vectorized Wiener Process)\n",
        "    # We generate (N x n_sims) random shocks at once\n",
        "    Z = np.random.normal(0, 1, (N, n_sims))\n",
        "\n",
        "    # 4. Apply GBM Formula\n",
        "    # Drift Term: Deterministic trend minus volatility drag\n",
        "    drift = (mu - 0.5 * sigma**2) * dt\n",
        "\n",
        "    # Diffusion Term: Scaled random shocks\n",
        "    diffusion = sigma * np.sqrt(dt) * Z\n",
        "\n",
        "    # 5. Compute Price Path\n",
        "    # daily_log_returns = drift + diffusion\n",
        "    daily_returns = np.exp(drift + diffusion)\n",
        "\n",
        "    # We start with a row of 1s (representing the starting multiplier)\n",
        "    # Then we accumulate the products\n",
        "    price_paths = np.zeros((N + 1, n_sims))\n",
        "    price_paths[0] = S0\n",
        "\n",
        "    # Efficient Cumulative Product (cumprod)\n",
        "    # Instead of a loop, we multiply all returns cumulatively\n",
        "    price_paths[1:] = S0 * np.cumprod(daily_returns, axis=0)\n",
        "\n",
        "    return price_paths\n",
        "\n",
        "# --- TESTING THE FUNCTION (Scenario Analysis) ---\n",
        "\n",
        "# Define Parameters (Based on your Nifty 50 analysis)\n",
        "current_price = 21700 # Example Price\n",
        "mu_base = 0.12        # 12% Expected Return\n",
        "\n",
        "# Run Simulation 1: Low Volatility (Stable Market)\n",
        "paths_stable = simulate_gbm(S0=current_price, mu=mu_base, sigma=0.10, T=1, dt=1/252, n_sims=100)\n",
        "\n",
        "# Run Simulation 2: High Volatility (Panic Market)\n",
        "paths_panic = simulate_gbm(S0=current_price, mu=mu_base, sigma=0.30, T=1, dt=1/252, n_sims=100)\n",
        "\n",
        "# --- VISUALIZATION ---\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot Stable Market\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(paths_stable, color='green', alpha=0.1)\n",
        "plt.plot(paths_stable.mean(axis=1), color='black', linewidth=2, linestyle='--')\n",
        "plt.title('Scenario A: Stable Market (Vol=10%)')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot Panic Market\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(paths_panic, color='red', alpha=0.1)\n",
        "plt.plot(paths_panic.mean(axis=1), color='black', linewidth=2, linestyle='--')\n",
        "plt.title('Scenario B: High Volatility (Vol=30%)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"Day 6 Task Complete: GBM Function Implemented and Tested.\")"
      ],
      "metadata": {
        "id": "xWv8z8BrchVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 6: IMPLEMENTING THE GBM FUNCTION ---\n",
        "\n",
        "def GBM_simulation(S0, mu, sigma, T, dt, n_sims):\n",
        "    \"\"\"\n",
        "    A simple function to simulate Geometric Brownian Motion price paths.\n",
        "    \"\"\"\n",
        "    # 1. Setup\n",
        "    N = int(T / dt) # Number of time steps\n",
        "    np.random.seed(42) # Ensure we get the same random numbers every time\n",
        "\n",
        "    # 2. Generate Random Shocks (The 'Z' values)\n",
        "    # We generate a matrix of random numbers [Time Steps x Number of Simulations]\n",
        "    Z = np.random.normal(0, 1, (N, n_sims))\n",
        "\n",
        "    # 3. Apply the Formula\n",
        "    # Drift = (mu - 0.5 * sigma^2) * dt\n",
        "    drift = (mu - 0.5 * sigma**2) * dt\n",
        "\n",
        "    # Diffusion = sigma * sqrt(dt) * Z\n",
        "    diffusion = sigma * np.sqrt(dt) * Z\n",
        "\n",
        "    # Calculate Daily Returns\n",
        "    daily_returns = np.exp(drift + diffusion)\n",
        "\n",
        "    # 4. Construct Price Paths\n",
        "    # Start with a matrix of zeros\n",
        "    price_paths = np.zeros((N + 1, n_sims))\n",
        "    price_paths[0] = S0\n",
        "\n",
        "    # Calculate future prices\n",
        "    # We use cumulative product because returns compound over time\n",
        "    price_paths[1:] = S0 * np.cumprod(daily_returns, axis=0)\n",
        "\n",
        "    return price_paths\n",
        "\n",
        "# --- TESTING THE FUNCTION ---\n",
        "# We test it with the Nifty 50 parameters we found earlier\n",
        "current_price = 21700  # Example S0\n",
        "mu_nifty = 0.12        # Example Drift\n",
        "sigma_nifty = 0.10     # Example Volatility (10%)\n",
        "\n",
        "# Call the function\n",
        "simulated_paths = GBM_simulation(S0=current_price, mu=mu_nifty, sigma=sigma_nifty, T=1, dt=1/252, n_sims=50)\n",
        "\n",
        "# Plot the result\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(simulated_paths, lw=1, alpha=0.6)\n",
        "plt.title('Testing the GBM Simulation Function (50 Paths)')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Function Test Complete. Generated {simulated_paths.shape[1]} paths over {simulated_paths.shape[0]-1} days.\")"
      ],
      "metadata": {
        "id": "_6u_78xSdfMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 7: MONTE CARLO OPTION PRICING (European Call) ---\n",
        "\n",
        "# 1. SETUP PARAMETERS (Risk-Neutral Inputs)\n",
        "S0 = 21700          # Current Price of Nifty 50\n",
        "K = 22000           # Strike Price (Target Price)\n",
        "r = 0.07            # Risk-Free Rate (7% - e.g., India 10Y Bond)\n",
        "sigma = 0.10        # Volatility (10%)\n",
        "T = 1.0             # Time Horizon (1 Year)\n",
        "dt = 1/252          # Time Step\n",
        "N = int(T/dt)       # Total Steps\n",
        "M = 50000           # Number of Simulations (High M for accuracy)\n",
        "\n",
        "print(f\"Pricing European Call Option:\")\n",
        "print(f\"Spot: {S0} | Strike: {K} | Risk-Free Rate: {r:.0%} | Vol: {sigma:.0%}\")\n",
        "\n",
        "# 2. GENERATE PRICE PATHS (Vectorized)\n",
        "np.random.seed(42)\n",
        "Z = np.random.normal(0, 1, (N, M))\n",
        "\n",
        "# Risk-Neutral Drift: (r - 0.5 * sigma^2)\n",
        "drift = (r - 0.5 * sigma**2) * dt\n",
        "diffusion = sigma * np.sqrt(dt) * Z\n",
        "daily_returns = np.exp(drift + diffusion)\n",
        "\n",
        "# Calculate Terminal Price (ST) only\n",
        "# Optimization: We use cumprod just to get the final multiplier\n",
        "total_growth = np.prod(daily_returns, axis=0)\n",
        "ST = S0 * total_growth\n",
        "\n",
        "# 3. CALCULATE PAYOFF\n",
        "# Call Payoff = max(ST - K, 0)\n",
        "payoffs = np.maximum(ST - K, 0)\n",
        "\n",
        "# 4. DISCOUNT TO PRESENT VALUE\n",
        "# Price = Average Payoff * e^(-rT)\n",
        "mean_payoff = np.mean(payoffs)\n",
        "option_price = mean_payoff * np.exp(-r * T)\n",
        "\n",
        "# 5. VISUALIZATION\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Filter out zero payoffs for a clearer histogram\n",
        "profitable_outcomes = ST[ST > K]\n",
        "plt.hist(ST, bins=50, color='skyblue', alpha=0.7, label='Final Prices')\n",
        "plt.axvline(K, color='red', linestyle='--', linewidth=2, label=f'Strike Price ({K})')\n",
        "plt.title('Monte Carlo Option Pricing Distribution')\n",
        "plt.xlabel('Price at Maturity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 6. RESULTS\n",
        "print(\"-\" * 40)\n",
        "print(f\"Calculated Call Option Price: Rs. {option_price:.2f}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Probability of Profit (ITM):  {np.mean(ST > K)*100:.2f}%\")"
      ],
      "metadata": {
        "id": "ING2-QJiSgQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 8: PRICING A PUT OPTION WITH CONFIDENCE INTERVALS ---\n",
        "\n",
        "# 1. SETUP PARAMETERS (Risk-Neutral World)\n",
        "S0 = 21700          # Current Nifty 50 Price\n",
        "K = 21500           # Strike Price (We profit if market falls below this)\n",
        "r = 0.07            # Risk-Free Rate (7%)\n",
        "sigma = 0.10        # Volatility (10%)\n",
        "T = 1.0             # Time Horizon (1 Year)\n",
        "dt = 1/252          # Time Step\n",
        "N = int(T/dt)       # Steps\n",
        "M = 50000           # Simulations (Higher M = Smaller Confidence Interval)\n",
        "\n",
        "print(f\"Pricing European PUT Option:\")\n",
        "print(f\"S0: {S0} | Strike: {K} | Risk-Free Rate: {r:.0%} | Vol: {sigma:.0%}\")\n",
        "print(f\"Simulations: {M}\")\n",
        "\n",
        "# 2. VECTORIZED SIMULATION\n",
        "np.random.seed(42)\n",
        "Z = np.random.normal(0, 1, (N, M))\n",
        "\n",
        "# Risk-Neutral GBM Formula\n",
        "drift = (r - 0.5 * sigma**2) * dt\n",
        "diffusion = sigma * np.sqrt(dt) * Z\n",
        "daily_returns = np.exp(drift + diffusion)\n",
        "\n",
        "# Calculate Terminal Prices only (Optimization: We don't need the whole path for pricing)\n",
        "# We can just multiply all returns to jump to the end\n",
        "total_returns = np.prod(daily_returns, axis=0)\n",
        "ST = S0 * total_returns\n",
        "\n",
        "# 3. CALCULATE PUT PAYOFF\n",
        "# Put Payoff = max(Strike - S_T, 0) -> Profit when S_T is LOW\n",
        "payoffs = np.maximum(K - ST, 0)\n",
        "\n",
        "# Discount back to present value\n",
        "discounted_payoffs = payoffs * np.exp(-r * T)\n",
        "\n",
        "# 4. STATISTICS & CONFIDENCE INTERVALS\n",
        "# Standard Error = StdDev / sqrt(M)\n",
        "option_price = np.mean(discounted_payoffs)\n",
        "std_error = np.std(discounted_payoffs) / np.sqrt(M)\n",
        "\n",
        "# 95% Confidence Interval (Z-score = 1.96)\n",
        "ci_lower = option_price - (1.96 * std_error)\n",
        "ci_upper = option_price + (1.96 * std_error)\n",
        "\n",
        "# 5. VISUALIZATION\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Histogram of Positive Payoffs (Ignoring the zeros makes the graph easier to read)\n",
        "positive_payoffs = payoffs[payoffs > 0]\n",
        "plt.hist(positive_payoffs, bins=50, color='#d62728', alpha=0.7, label='Profit Scenarios')\n",
        "\n",
        "plt.title(f'Distribution of Put Option Profits (In-The-Money scenarios only)')\n",
        "plt.xlabel('Payoff Amount (Rs)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 6. PROFESSIONAL REPORT\n",
        "print(\"-\" * 50)\n",
        "print(f\"MONTE CARLO PRICING RESULTS\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Put Option Price:   Rs. {option_price:.2f}\")\n",
        "print(f\"Standard Error:     Rs. {std_error:.4f}\")\n",
        "print(f\"95% Conf Interval:  [Rs. {ci_lower:.2f}, Rs. {ci_upper:.2f}]\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Analysis:\")\n",
        "print(f\"The simulation is 95% confident that the true price lies between\")\n",
        "print(f\"{ci_lower:.2f} and {ci_upper:.2f}. To make this range tighter,\")\n",
        "print(f\"we would need to increase the number of simulations (M).\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "DEXsG_Q0RS3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as si\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 9: MONTE CARLO vs. BLACK-SCHOLES FORMULA ---\n",
        "\n",
        "# 1. SETUP PARAMETERS\n",
        "S0 = 21700          # Current Price\n",
        "K = 22000           # Strike Price (Call Option)\n",
        "T = 1.0             # Time (1 Year)\n",
        "r = 0.07            # Risk-Free Rate (7%)\n",
        "sigma = 0.10        # Volatility (10%)\n",
        "\n",
        "# 2. METHOD A: BLACK-SCHOLES FORMULA (The \"Exact\" Analytical Solution)\n",
        "# Formula: C = S*N(d1) - K*e^(-rT)*N(d2)\n",
        "def black_scholes_call(S, K, T, r, sigma):\n",
        "    # d1 and d2 are the probability factors\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "\n",
        "    # N(x) is the Cumulative Normal Distribution Function\n",
        "    call_price = (S * si.norm.cdf(d1, 0.0, 1.0) -\n",
        "                  K * np.exp(-r * T) * si.norm.cdf(d2, 0.0, 1.0))\n",
        "    return call_price\n",
        "\n",
        "bs_price = black_scholes_call(S0, K, T, r, sigma)\n",
        "\n",
        "# 3. METHOD B: MONTE CARLO SIMULATION (The \"Approximation\")\n",
        "# We run simulations with increasing sizes to show convergence\n",
        "sim_sizes = [100, 1000, 5000, 10000, 50000, 100000]\n",
        "mc_prices = []\n",
        "errors = []\n",
        "\n",
        "print(f\"{'Simulations':<15} {'MC Price':<15} {'BS Price':<15} {'Error':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for M in sim_sizes:\n",
        "    # Quick Vectorized Monte Carlo\n",
        "    np.random.seed(42) # Consistent Randomness\n",
        "    Z = np.random.normal(0, 1, M)\n",
        "    ST = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z)\n",
        "    payoffs = np.maximum(ST - K, 0)\n",
        "    mc_price = np.mean(payoffs) * np.exp(-r * T)\n",
        "\n",
        "    mc_prices.append(mc_price)\n",
        "    error = abs(mc_price - bs_price)\n",
        "    errors.append(error)\n",
        "\n",
        "    print(f\"{M:<15} {mc_price:<15.2f} {bs_price:<15.2f} {error:<15.4f}\")\n",
        "\n",
        "# 4. VISUALIZATION OF CONVERGENCE\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the Monte Carlo Estimates (Blue Dots)\n",
        "plt.plot(sim_sizes, mc_prices, marker='o', linestyle='--', color='blue', label='Monte Carlo Estimate')\n",
        "\n",
        "# Plot the True Black-Scholes Price (Red Line)\n",
        "plt.axhline(bs_price, color='red', linewidth=2, label=f'Black-Scholes Price ({bs_price:.2f})')\n",
        "\n",
        "plt.xscale('log') # Use Log scale because we jump from 100 to 100,000\n",
        "plt.title('Convergence: Monte Carlo approaches Black-Scholes')\n",
        "plt.xlabel('Number of Simulations (Log Scale)')\n",
        "plt.ylabel('Option Price')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nConclusion:\")\n",
        "print(f\"With {sim_sizes[-1]} simulations, the difference is only Rs. {errors[-1]:.4f}.\")"
      ],
      "metadata": {
        "id": "AkUSQCZcEyZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 10: VARIANCE REDUCTION (ANTITHETIC SAMPLING) ---\n",
        "\n",
        "# 1. SETUP PARAMETERS\n",
        "S0 = 21700          # Current Price\n",
        "K = 22000           # Strike Price (Call Option)\n",
        "T = 1.0             # Time (1 Year)\n",
        "r = 0.07            # Risk-Free Rate\n",
        "sigma = 0.10        # Volatility\n",
        "M = 50000           # Number of Simulations\n",
        "\n",
        "print(f\"Comparison: Standard vs. Antithetic Sampling (M={M})\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# 2. METHOD A: STANDARD MONTE CARLO (The Baseline)\n",
        "np.random.seed(42)\n",
        "Z_standard = np.random.normal(0, 1, M)\n",
        "\n",
        "ST_standard = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z_standard)\n",
        "payoffs_standard = np.maximum(ST_standard - K, 0)\n",
        "price_standard = np.mean(payoffs_standard) * np.exp(-r * T)\n",
        "\n",
        "# Standard Error (Noise Level)\n",
        "se_standard = np.std(payoffs_standard * np.exp(-r * T)) / np.sqrt(M)\n",
        "\n",
        "\n",
        "# 3. METHOD B: ANTITHETIC SAMPLING (The Advanced Way)\n",
        "# We only need HALF the random numbers because we reuse them\n",
        "np.random.seed(42)\n",
        "Z_antithetic = np.random.normal(0, 1, int(M / 2))\n",
        "\n",
        "# Path 1: Use +Z (The Normal Path)\n",
        "ST_1 = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z_antithetic)\n",
        "\n",
        "# Path 2: Use -Z (The Mirror Path) - This is the \"Antithetic\" trick!\n",
        "ST_2 = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * (-Z_antithetic))\n",
        "\n",
        "# Calculate Payoffs for both\n",
        "payoff_1 = np.maximum(ST_1 - K, 0)\n",
        "payoff_2 = np.maximum(ST_2 - K, 0)\n",
        "\n",
        "# Average the pair BEFORE taking the total average\n",
        "# This pair (A + B)/2 is very stable\n",
        "pair_average = (payoff_1 + payoff_2) / 2\n",
        "price_antithetic = np.mean(pair_average) * np.exp(-r * T)\n",
        "\n",
        "# Standard Error of the PAIRS\n",
        "se_antithetic = np.std(pair_average * np.exp(-r * T)) / np.sqrt(int(M / 2))\n",
        "\n",
        "\n",
        "# 4. RESULTS COMPARISON\n",
        "variance_reduction = 1 - (se_antithetic / se_standard)\n",
        "\n",
        "print(f\"{'Method':<20} {'Price':<15} {'Standard Error (Noise)':<25}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Standard MC':<20} {price_standard:<15.4f} {se_standard:<25.4f}\")\n",
        "print(f\"{'Antithetic MC':<20} {price_antithetic:<15.4f} {se_antithetic:<25.4f}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"\\nSUCCESS: Antithetic Sampling reduced error by {variance_reduction:.1%}\")\n",
        "print(f\"This means we got a more precise answer without needing more data!\")\n",
        "\n",
        "# 5. VISUALIZATION OF CONVERGENCE\n",
        "# Let's show how fast they stabilize\n",
        "sim_sizes = range(100, 5000, 100)\n",
        "std_prices = []\n",
        "anti_prices = []\n",
        "\n",
        "for m in sim_sizes:\n",
        "    # Standard\n",
        "    z = np.random.normal(0, 1, m)\n",
        "    st = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * z)\n",
        "    p = np.mean(np.maximum(st - K, 0)) * np.exp(-r * T)\n",
        "    std_prices.append(p)\n",
        "\n",
        "    # Antithetic\n",
        "    z = np.random.normal(0, 1, int(m/2))\n",
        "    st1 = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * z)\n",
        "    st2 = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * -z)\n",
        "    p = np.mean((np.maximum(st1 - K, 0) + np.maximum(st2 - K, 0))/2) * np.exp(-r * T)\n",
        "    anti_prices.append(p)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(sim_sizes, std_prices, color='blue', alpha=0.4, label='Standard MC (Jittery)')\n",
        "plt.plot(sim_sizes, anti_prices, color='red', linewidth=2, label='Antithetic MC (Stable)')\n",
        "plt.axhline(price_antithetic, color='black', linestyle='--')\n",
        "plt.title('Comparison: Antithetic Sampling Converges Faster')\n",
        "plt.xlabel('Number of Simulations')\n",
        "plt.ylabel('Calculated Price')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FuHpI1deFCpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# WEEK 3: INFORMATION THEORETIC METHODS\n",
        "# DAY 11: SHANNON ENTROPY OF NIFTY 50 RETURNS\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. DOWNLOAD DATA\n",
        "# ---------------------------------------------------------\n",
        "ticker = \"^NSEI\"  # Nifty 50 Ticker\n",
        "start_date = \"2023-01-01\"\n",
        "end_date = \"2024-01-01\"\n",
        "\n",
        "print(f\"Downloading data for {ticker}...\")\n",
        "data = yf.download(ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Calculate Log Returns (standard for entropy analysis)\n",
        "data['Log_Ret'] = np.log(data['Close'] / data['Close'].shift(1))\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# 2. DISCRETIZATION (BINNING)\n",
        "# ---------------------------------------------------------\n",
        "# Entropy requires discrete states (bins).\n",
        "# We convert continuous returns into a histogram.\n",
        "num_bins = 50  # Dividing the returns into 50 distinct \"buckets\"\n",
        "\n",
        "# np.histogram returns the frequency count (counts) and the bin edges\n",
        "counts, bin_edges = np.histogram(data['Log_Ret'], bins=num_bins, density=False)\n",
        "\n",
        "# 3. CALCULATE PROBABILITIES (p(x))\n",
        "# ---------------------------------------------------------\n",
        "# Probability = Count in Bin / Total Days\n",
        "probabilities = counts / np.sum(counts)\n",
        "\n",
        "# Remove zero probabilities to avoid log(0) error\n",
        "# (In math, 0*log(0) is 0, but in code it causes NaN)\n",
        "probabilities = probabilities[probabilities > 0]\n",
        "\n",
        "# 4. CALCULATE SHANNON ENTROPY (H)\n",
        "# ---------------------------------------------------------\n",
        "# Formula: H(X) = - sum( p(x) * log2( p(x) ) )\n",
        "shannon_entropy = -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "# Maximum Possible Entropy (Uniform Distribution)\n",
        "max_entropy = np.log2(num_bins)\n",
        "\n",
        "# Efficiency Ratio (How random is the market?)\n",
        "efficiency = shannon_entropy / max_entropy\n",
        "\n",
        "# 5. OUTPUT RESULTS\n",
        "# ---------------------------------------------------------\n",
        "print(\"-\" * 50)\n",
        "print(f\"SHANNON ENTROPY ANALYSIS ({start_date} to {end_date})\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Number of Trading Days: {len(data)}\")\n",
        "print(f\"Number of Bins Used:    {num_bins}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Shannon Entropy (H):    {shannon_entropy:.4f} bits\")\n",
        "print(f\"Max Possible Entropy:   {max_entropy:.4f} bits\")\n",
        "print(f\"Market Efficiency:      {efficiency:.2%}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Interpretation\n",
        "if efficiency > 0.9:\n",
        "    print(\"INTERPRETATION: High Entropy. Market is very random (Efficient).\")\n",
        "else:\n",
        "    print(\"INTERPRETATION: Lower Entropy. Market shows structure/clustering.\")\n",
        "\n",
        "# 6. VISUALIZATION\n",
        "# ---------------------------------------------------------\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(data['Log_Ret'], bins=num_bins, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.title(f\"Discretized Return Distribution (Entropy = {shannon_entropy:.2f} bits)\", fontsize=14)\n",
        "plt.xlabel(\"Log Returns\")\n",
        "plt.ylabel(\"Frequency (Days)\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZTE5cxHl7uue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# WEEK 3: INFORMATION THEORETIC METHODS\n",
        "# DAY 12: RENYI ENTROPY (The Spectrum of Risk)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. PREPARE DATA (Same as Day 11)\n",
        "# ---------------------------------------------------------\n",
        "ticker = \"^NSEI\"\n",
        "data = yf.download(ticker, start=\"2023-01-01\", end=\"2024-01-01\")\n",
        "data['Log_Ret'] = np.log(data['Close'] / data['Close'].shift(1))\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Discretize returns into 50 bins\n",
        "counts, bin_edges = np.histogram(data['Log_Ret'], bins=50, density=False)\n",
        "probs = counts / np.sum(counts)\n",
        "probs = probs[probs > 0]  # Filter out zero probabilities\n",
        "\n",
        "# 2. DEFINE RENYI ENTROPY FUNCTION\n",
        "# ---------------------------------------------------------\n",
        "def renyi_entropy(probabilities, alpha):\n",
        "    \"\"\"\n",
        "    Calculates Rényi Entropy of order alpha.\n",
        "    Formula: H_alpha = (1 / (1-alpha)) * log2( sum(p^alpha) )\n",
        "    \"\"\"\n",
        "    # Special Case: Alpha -> 1 is Shannon Entropy\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "    # General Case: Alpha != 1\n",
        "    term = np.sum(np.power(probabilities, alpha))\n",
        "    return (1 / (1 - alpha)) * np.log2(term)\n",
        "\n",
        "# 3. CALCULATE FOR DIFFERENT ALPHAS\n",
        "# ---------------------------------------------------------\n",
        "alphas = [0.5, 1, 2]\n",
        "results = {}\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"RENYI ENTROPY ANALYSIS (Spectrum of Risk)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for a in alphas:\n",
        "    h_val = renyi_entropy(probs, a)\n",
        "    results[a] = h_val\n",
        "\n",
        "    # Interpretation text based on Alpha\n",
        "    tag = \"\"\n",
        "    if a == 0.5: tag = \"(Focus on Rare Events/Tails)\"\n",
        "    elif a == 1: tag = \"(Shannon / Balanced)\"\n",
        "    elif a == 2: tag = \"(Collision / Stability)\"\n",
        "\n",
        "    print(f\"Alpha = {a}  : {h_val:.4f} bits  {tag}\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# 4. ANALYZE THE \"ENTROPY GAP\"\n",
        "# ---------------------------------------------------------\n",
        "# The gap between H(0.5) and H(2) shows how \"heavy\" the tails are.\n",
        "gap = results[0.5] - results[2]\n",
        "print(f\"Risk Spectrum Gap (H_0.5 - H_2): {gap:.4f} bits\")\n",
        "\n",
        "if gap > 1.0:\n",
        "    print(\"CONCLUSION: Large Gap -> Market has significant Tail Risk (Fat Tails).\")\n",
        "else:\n",
        "    print(\"CONCLUSION: Small Gap -> Market behaves closer to a Normal Distribution.\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# 5. VISUALIZATION\n",
        "# ---------------------------------------------------------\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([str(a) for a in alphas], results.values(), color=['salmon', 'skyblue', 'lightgreen'], edgecolor='black')\n",
        "plt.title(\"Rényi Entropy Spectrum (Nifty 50)\", fontsize=14)\n",
        "plt.ylabel(\"Entropy (Bits)\")\n",
        "plt.xlabel(\"Alpha (Sensitivity Parameter)\")\n",
        "plt.ylim(0, max(results.values()) + 1)\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for i, v in enumerate(results.values()):\n",
        "    plt.text(i, v + 0.1, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kSVdEZgC8B8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# WEEK 3: INFORMATION THEORETIC METHODS\n",
        "# DAY 13: ROLLING ENTROPY VS. ROLLING VOLATILITY\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# 1. PREPARE DATA\n",
        "# ---------------------------------------------------------\n",
        "ticker = \"^NSEI\"\n",
        "data = yf.download(ticker, start=\"2023-01-01\", end=\"2024-01-01\")\n",
        "data['Log_Ret'] = np.log(data['Close'] / data['Close'].shift(1))\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# 2. DEFINE PARAMETERS\n",
        "# ---------------------------------------------------------\n",
        "window_size = 30  # 30-Day Rolling Window\n",
        "num_bins = 20     # Bins for local entropy calculation\n",
        "\n",
        "# Arrays to store results\n",
        "rolling_dates = []\n",
        "rolling_vol = []\n",
        "rolling_ent = []\n",
        "\n",
        "# 3. ROLLING WINDOW CALCULATION\n",
        "# ---------------------------------------------------------\n",
        "print(\"Calculated Rolling Metrics...\")\n",
        "\n",
        "# Loop through the data using a sliding window\n",
        "for i in range(window_size, len(data)):\n",
        "    # Slice the window (past 30 days)\n",
        "    window_data = data['Log_Ret'].iloc[i-window_size : i]\n",
        "    current_date = data.index[i]\n",
        "\n",
        "    # A. Calculate Volatility (Std Dev)\n",
        "    vol = window_data.std()\n",
        "\n",
        "    # B. Calculate Entropy (Shannon)\n",
        "    # We re-bin the data inside the window to measure local randomness\n",
        "    counts, _ = np.histogram(window_data, bins=num_bins, density=False)\n",
        "    probs = counts / np.sum(counts)\n",
        "    probs = probs[probs > 0] # Remove zeros\n",
        "    ent = -np.sum(probs * np.log2(probs))\n",
        "\n",
        "    # Store\n",
        "    rolling_dates.append(current_date)\n",
        "    rolling_vol.append(vol)\n",
        "    rolling_ent.append(ent)\n",
        "\n",
        "# Create a DataFrame for easy plotting\n",
        "df_roll = pd.DataFrame({\n",
        "    'Date': rolling_dates,\n",
        "    'Volatility': rolling_vol,\n",
        "    'Entropy': rolling_ent\n",
        "})\n",
        "df_roll.set_index('Date', inplace=True)\n",
        "\n",
        "# 4. NORMALIZE (Z-SCORE) FOR COMPARISON\n",
        "# ---------------------------------------------------------\n",
        "# Since Volatility is small (0.01) and Entropy is large (3.0),\n",
        "# we must normalize them to compare their SHAPE.\n",
        "df_roll['Z_Vol'] = stats.zscore(df_roll['Volatility'])\n",
        "df_roll['Z_Ent'] = stats.zscore(df_roll['Entropy'])\n",
        "\n",
        "# 5. STATISTICAL CORRELATION\n",
        "# ---------------------------------------------------------\n",
        "corr = df_roll['Volatility'].corr(df_roll['Entropy'])\n",
        "print(\"-\" * 50)\n",
        "print(f\"CORRELATION ANALYSIS (Window = {window_size} days)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Correlation between Volatility & Entropy: {corr:.4f}\")\n",
        "\n",
        "if corr > 0.8:\n",
        "    print(\"INTERPRETATION: Strong positive relationship (Market is Normal).\")\n",
        "elif corr > 0.5:\n",
        "    print(\"INTERPRETATION: Moderate relationship.\")\n",
        "else:\n",
        "    print(\"INTERPRETATION: Divergence detected! Volatility and Entropy are disconnecting.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 6. VISUALIZATION\n",
        "# ---------------------------------------------------------\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot normalized values\n",
        "plt.plot(df_roll.index, df_roll['Z_Vol'], label='Rolling Volatility (Risk)', color='red', linewidth=1.5)\n",
        "plt.plot(df_roll.index, df_roll['Z_Ent'], label='Rolling Entropy (Uncertainty)', color='blue', linestyle='--', linewidth=1.5)\n",
        "\n",
        "plt.title(f\"Volatility vs. Entropy: Divergence Analysis (Corr: {corr:.2f})\", fontsize=14)\n",
        "plt.ylabel(\"Normalized Score (Z-Score)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(0, color='black', linewidth=0.8)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mUTZADu98cHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# WEEK 3: INFORMATION THEORETIC METHODS\n",
        "# DAY 14: KULLBACK-LEIBLER (KL) DIVERGENCE AUDIT\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# 1. PREPARE DATA\n",
        "# ---------------------------------------------------------\n",
        "ticker = \"^NSEI\"\n",
        "data = yf.download(ticker, start=\"2023-01-01\", end=\"2024-01-01\")\n",
        "data['Log_Ret'] = np.log(data['Close'] / data['Close'].shift(1))\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "returns = data['Log_Ret'].values\n",
        "mu = np.mean(returns)\n",
        "sigma = np.std(returns)\n",
        "\n",
        "# 2. DISCRETIZATION (Create P and Q)\n",
        "# ---------------------------------------------------------\n",
        "# We need to bin the data to compare probabilities discrete-ly.\n",
        "num_bins = 60\n",
        "range_min = min(returns)\n",
        "range_max = max(returns)\n",
        "\n",
        "# A. Empirical Distribution (P) - The Reality\n",
        "counts, bin_edges = np.histogram(returns, bins=num_bins, density=False)\n",
        "P = counts / np.sum(counts)\n",
        "\n",
        "# B. Theoretical Distribution (Q) - The Assumption (Normal Model)\n",
        "# We calculate the Gaussian probability for the center of each bin\n",
        "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
        "Q = stats.norm.pdf(bin_centers, mu, sigma)\n",
        "\n",
        "# Normalize Q so it sums to 1 (like a probability mass function)\n",
        "Q = Q / np.sum(Q)\n",
        "\n",
        "# 3. CALCULATE KL DIVERGENCE\n",
        "# ---------------------------------------------------------\n",
        "# Formula: D_KL(P || Q) = sum( P(i) * log2( P(i) / Q(i) ) )\n",
        "\n",
        "# Safety: Avoid division by zero or log(0)\n",
        "# We only calculate where P > 0 and Q > 0\n",
        "mask = (P > 0) & (Q > 0)\n",
        "P_safe = P[mask]\n",
        "Q_safe = Q[mask]\n",
        "\n",
        "kl_divergence = np.sum(P_safe * np.log2(P_safe / Q_safe))\n",
        "\n",
        "# 4. PRINT RESULTS\n",
        "# ---------------------------------------------------------\n",
        "print(\"-\" * 50)\n",
        "print(f\"KL DIVERGENCE AUDIT (Nifty 50)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Observed Mean: {mu:.6f}\")\n",
        "print(f\"Observed Vol:  {sigma:.6f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"KL Divergence (Bits): {kl_divergence:.5f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if kl_divergence > 0.05:\n",
        "    print(\"CONCLUSION: FAILED. Significant Information Loss.\")\n",
        "    print(\"The Market is NOT Normal. (Fat Tails Detected)\")\n",
        "else:\n",
        "    print(\"CONCLUSION: PASSED. The Market is effectively Normal.\")\n",
        "\n",
        "# 5. VISUALIZATION (Visual Proof)\n",
        "# ---------------------------------------------------------\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot P (Reality) as bars\n",
        "plt.bar(bin_centers, P, width=(bin_edges[1]-bin_edges[0]), alpha=0.5, color='blue', label='Empirical (Reality) P', edgecolor='black')\n",
        "\n",
        "# Plot Q (Model) as a smooth line\n",
        "plt.plot(bin_centers, Q, color='red', linewidth=3, label='Gaussian (Model) Q')\n",
        "\n",
        "plt.title(f\"Visualizing the Entropy Gap (KL Div = {kl_divergence:.4f})\", fontsize=14)\n",
        "plt.xlabel(\"Log Returns\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mzKA8LDx8vKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- DAY 16: PROJECT SETUP & DATA PIPELINE ---\n",
        "\n",
        "# 1. DEFINE PARAMETERS\n",
        "TICKER = '^NSEI'    # Nifty 50 Index\n",
        "START_DATE = '2023-01-01'\n",
        "END_DATE = '2024-01-01'\n",
        "RISK_FREE_RATE = 0.07 # 7% India 10Y Bond Yield\n",
        "\n",
        "# 2. DATA ACQUISITION\n",
        "print(f\"Fetching data for {TICKER} from {START_DATE} to {END_DATE}...\")\n",
        "data = yf.download(TICKER, start=START_DATE, end=END_DATE, progress=False)\n",
        "\n",
        "# 3. DATA PROCESSING\n",
        "df = pd.DataFrame()\n",
        "df['Price'] = data['Close']\n",
        "\n",
        "# Calculate Log Returns (The engine of our simulation)\n",
        "df['Log_Return'] = np.log(df['Price'] / df['Price'].shift(1))\n",
        "\n",
        "# Calculate Rolling Volatility (21-day trading month)\n",
        "# We calculate annualized volatility for each day\n",
        "df['Volatility_21d'] = df['Log_Return'].rolling(window=21).std() * np.sqrt(252)\n",
        "\n",
        "# Drop NaN values created by rolling windows\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 4. EXPLORATORY DATA ANALYSIS (EDA)\n",
        "# We need to know the 'Last Price' and 'Current Volatility' to set up our Option pricing tomorrow\n",
        "S0 = df['Price'].iloc[-1]\n",
        "current_vol = df['Volatility_21d'].iloc[-1]\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"PROJECT DATASET READY\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Start Price (Jan 2023):  {df['Price'].iloc[0]:.2f}\")\n",
        "print(f\"End Price (Dec 2023):    {S0:.2f} (S0 for Simulation)\")\n",
        "print(f\"Current Volatility:      {current_vol:.2%}\")\n",
        "print(f\"Total Trading Days:      {len(df)}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 5. VISUALIZATION\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Nifty 50 Price', color=color)\n",
        "ax1.plot(df.index, df['Price'], color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Annualized Volatility (21-Day)', color=color)\n",
        "ax2.plot(df.index, df['Volatility_21d'], color=color, linestyle='--', alpha=0.5)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Day 16: Project Data - Price vs. Volatility Regime')\n",
        "fig.tight_layout()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig(\"day16_project_data.png\")\n",
        "plt.show()\n",
        "\n",
        "# 6. SAVE DATA FOR FUTURE DAYS\n",
        "df.to_csv(\"nifty50_project_data.csv\")\n",
        "print(\"Data saved to 'nifty50_project_data.csv'.\")"
      ],
      "metadata": {
        "id": "CjEPxxu1MMjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# --- DAY 17: THE MONTE CARLO PRICING ENGINE ---\n",
        "\n",
        "# 1. LOAD DATA (From Day 16)\n",
        "df = pd.read_csv(\"nifty50_project_data.csv\", index_col=0)\n",
        "S0 = df['Price'].iloc[-1]       # Last observed price (Dec 2023)\n",
        "sigma = df['Volatility_21d'].iloc[-1] # Last observed volatility\n",
        "r = 0.07                        # Risk-Free Rate (7%)\n",
        "\n",
        "# 2. DEFINE OPTION CONTRACT\n",
        "# Let's price a \"At-The-Money\" (ATM) Call Option for 1 Month\n",
        "K = S0                          # Strike Price = Current Price\n",
        "T = 1/12                        # Time = 1 Month (0.083 years)\n",
        "M = 100000                      # Number of Simulations (High precision)\n",
        "\n",
        "print(f\"--- CONTRACT DETAILS ---\")\n",
        "print(f\"Asset: Nifty 50 | Spot: {S0:.2f} | Strike: {K:.2f}\")\n",
        "print(f\"Volatility: {sigma:.2%} | Time: 1 Month\")\n",
        "\n",
        "# 3. RUN SIMULATION (Vectorized)\n",
        "np.random.seed(42) # For reproducibility\n",
        "Z = np.random.normal(0, 1, M)\n",
        "\n",
        "# Geometric Brownian Motion Formula\n",
        "# ST = S0 * exp( (r - 0.5*sigma^2)T + sigma*sqrt(T)Z )\n",
        "drift = (r - 0.5 * sigma**2) * T\n",
        "diffusion = sigma * np.sqrt(T) * Z\n",
        "ST = S0 * np.exp(drift + diffusion)\n",
        "\n",
        "# 4. CALCULATE PRICE\n",
        "# Call Payoff = Max(ST - K, 0)\n",
        "payoffs = np.maximum(ST - K, 0)\n",
        "discounted_price = np.mean(payoffs) * np.exp(-r * T)\n",
        "\n",
        "# 5. CALCULATE ANALYTICAL PRICE (Black-Scholes) FOR COMPARISON\n",
        "# We need this to show the \"Standard\" benchmark\n",
        "d1 = (np.log(S0 / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "d2 = d1 - sigma * np.sqrt(T)\n",
        "bs_price = (S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2))\n",
        "\n",
        "# 6. RESULTS\n",
        "print(f\"\\n--- PRICING RESULTS ---\")\n",
        "print(f\"Monte Carlo Price:   Rs. {discounted_price:.2f}\")\n",
        "print(f\"Black-Scholes Price: Rs. {bs_price:.2f}\")\n",
        "print(f\"Difference:          Rs. {abs(discounted_price - bs_price):.4f}\")\n",
        "\n",
        "# 7. SAVE SIMULATION DATA FOR DAY 18\n",
        "# We need the 'ST' (Terminal Prices) to measure Entropy tomorrow!\n",
        "np.save(\"simulated_prices.npy\", ST)\n",
        "print(\"\\nSimulated terminal prices saved to 'simulated_prices.npy'\")\n",
        "\n",
        "# 8. VISUALIZATION\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(ST, bins=100, density=True, alpha=0.6, color='blue', label='Simulated Outcome (GBM)')\n",
        "plt.axvline(K, color='red', linestyle='--', label=f'Strike Price ({K:.0f})')\n",
        "plt.title(f'Day 17: Projected Price Distribution (N={M})')\n",
        "plt.xlabel('Nifty 50 Price at Expiry')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig(\"day17_simulation.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1tLSIHvMy2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import entropy, norm\n",
        "\n",
        "# --- DAY 18: THE ENTROPY AUDIT ---\n",
        "\n",
        "# 1. LOAD DATA\n",
        "# Load Real World Data (Day 16)\n",
        "df = pd.read_csv(\"nifty50_project_data.csv\", index_col=0)\n",
        "real_returns = df['Log_Return'].values\n",
        "\n",
        "# Load Simulation Parameters (Day 17)\n",
        "# We regenerate the \"Model Returns\" to compare apples-to-apples\n",
        "mu = real_returns.mean()\n",
        "sigma = real_returns.std()\n",
        "M = len(real_returns) # Same number of days for fair comparison\n",
        "\n",
        "# 2. GENERATE MODEL WORLD\n",
        "# This is what the Black-Scholes model *thinks* the market looks like (Perfect Normal)\n",
        "np.random.seed(42)\n",
        "model_returns = np.random.normal(mu, sigma, M)\n",
        "\n",
        "# 3. COMPUTE ENTROPY\n",
        "def get_distribution_probs(data, bins=50):\n",
        "    counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
        "    probs = counts / np.sum(counts)\n",
        "    return probs + 1e-10 # Add small epsilon to avoid log(0)\n",
        "\n",
        "# A. Real Entropy (The Chaos of Reality)\n",
        "p_real = get_distribution_probs(real_returns)\n",
        "H_real = entropy(p_real)\n",
        "\n",
        "# B. Model Entropy (The Cleanliness of Math)\n",
        "p_model = get_distribution_probs(model_returns)\n",
        "H_model = entropy(p_model)\n",
        "\n",
        "# 4. COMPUTE KL DIVERGENCE (The Error Metric)\n",
        "# How much information is lost if we use the Model to describe Reality?\n",
        "kl_div = entropy(p_real, p_model)\n",
        "\n",
        "# 5. RESULTS REPORT\n",
        "print(f\"--- DAY 18: ENTROPY AUDIT REPORT ---\")\n",
        "print(f\"Real Market Entropy:   {H_real:.4f} bits (More Chaotic)\")\n",
        "print(f\"Model Assumed Entropy: {H_model:.4f} bits (Too Structured)\")\n",
        "print(f\"KL Divergence (Error): {kl_div:.4f}\")\n",
        "\n",
        "if H_real > H_model:\n",
        "    print(\"\\nCONCLUSION: The Real Market carries more 'Uncertainty' than the Model predicts.\")\n",
        "    print(\"The Standard Model is UNDER-ESTIMATING risk.\")\n",
        "else:\n",
        "    print(\"\\nCONCLUSION: The Model is conservative enough.\")\n",
        "\n",
        "# 6. VISUALIZATION\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot Real Returns (Blue)\n",
        "plt.hist(real_returns, bins=50, density=True, alpha=0.5, color='blue', label='Real Nifty 50 Returns')\n",
        "\n",
        "# Plot Model Returns (Red Line)\n",
        "# We plot the Bell Curve that Day 17 used\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = norm.pdf(x, mu, sigma)\n",
        "plt.plot(x, p, 'r', linewidth=2, label='Model Assumption (Normal)')\n",
        "\n",
        "plt.title(f'Reality vs. Model Assumption\\nKL Divergence Error = {kl_div:.4f}')\n",
        "plt.xlabel('Daily Returns')\n",
        "plt.ylabel('Probability')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig(\"day18_entropy_audit.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B11e7hBDNfuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "\n",
        "# --- DAY 19: FINAL INTEGRATED VISUALIZATION ---\n",
        "\n",
        "# 1. LOAD DATA (From previous days)\n",
        "df = pd.read_csv(\"nifty50_project_data.csv\", index_col=0)\n",
        "real_returns = df['Log_Return'].values\n",
        "sim_prices = np.load(\"simulated_prices.npy\") # From Day 17\n",
        "\n",
        "# 2. SETUP THE MASTER PLOT\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle('Final Project Analysis - The \"Entropy Gap\"', fontsize=16)\n",
        "\n",
        "# --- LEFT PANEL: THE PRICING MODEL (Day 17) ---\n",
        "# This shows the \"Future\" according to Monte Carlo\n",
        "sns.histplot(sim_prices, bins=50, kde=True, color='green', ax=ax1, stat='density')\n",
        "ax1.set_title('Step 1: Monte Carlo Pricing (Simulated Future)')\n",
        "ax1.set_xlabel('Projected Price of Nifty 50')\n",
        "ax1.set_ylabel('Probability')\n",
        "ax1.axvline(np.mean(sim_prices), color='black', linestyle='--', label=f'Mean Price: {np.mean(sim_prices):.0f}')\n",
        "ax1.legend()\n",
        "\n",
        "# --- RIGHT PANEL: THE ENTROPY AUDIT (Day 18) ---\n",
        "# This shows the \"Error\" in the model's assumptions\n",
        "mu, sigma = real_returns.mean(), real_returns.std()\n",
        "x = np.linspace(real_returns.min(), real_returns.max(), 100)\n",
        "pdf_model = norm.pdf(x, mu, sigma)\n",
        "\n",
        "# Plot Reality (Blue)\n",
        "ax2.hist(real_returns, bins=50, density=True, alpha=0.5, color='blue', label='Real Market (High Entropy)')\n",
        "# Plot Model (Red)\n",
        "ax2.plot(x, pdf_model, 'r-', linewidth=3, label='Model Assumption (Low Entropy)')\n",
        "\n",
        "ax2.set_title('Step 2: The Entropy Audit (Reality Check)')\n",
        "ax2.set_xlabel('Daily Log Returns')\n",
        "ax2.legend()\n",
        "ax2.text(0.05, 0.9, \"FAT TAILS DETECTED\", transform=ax2.transAxes, color='red', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"day19_master_plot.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Final Master Plot generated. Use 'day19_master_plot.png' in your report.\")"
      ],
      "metadata": {
        "id": "QdTRIQ1hN8kh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}